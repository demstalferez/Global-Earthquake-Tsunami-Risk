# Documentaci√≥n T√©cnica del Panel de Inteligencia S√≠smico

## üìê Arquitectura del Sistema

### Estructura Modular

El panel est√° dise√±ado con una arquitectura modular para facilitar el mantenimiento, escalabilidad y colaboraci√≥n:

```
app/
‚îú‚îÄ‚îÄ app.py                     # Orquestador principal
‚îú‚îÄ‚îÄ components/                # M√≥dulos de UI
‚îÇ   ‚îú‚îÄ‚îÄ sidebar.py            # Controles de filtrado
‚îÇ   ‚îú‚îÄ‚îÄ intro.py              # Presentaci√≥n y contexto
‚îÇ   ‚îú‚îÄ‚îÄ eda.py                # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ conclusions.py        # Hallazgos y recomendaciones
‚îÇ   ‚îî‚îÄ‚îÄ ml.py                 # Machine Learning (futuro)
‚îú‚îÄ‚îÄ utils/                    # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py        # Gesti√≥n de datos
‚îÇ   ‚îî‚îÄ‚îÄ styles.py             # Estilos CSS
‚îî‚îÄ‚îÄ .streamlit/               # Configuraci√≥n
    ‚îî‚îÄ‚îÄ config.toml           # Tema y ajustes
```

### Flujo de Datos

```
CSV File ‚Üí load_data() ‚Üí DataFrame ‚Üí Filters ‚Üí Filtered DataFrame ‚Üí Visualizations
                ‚Üì
            Cache (1h TTL)
                ‚Üì
        Feature Engineering
                ‚Üì
        Derived Columns
```

## üîß Componentes Principales

### 1. `app.py` - Aplicaci√≥n Principal

**Responsabilidades:**
- Inicializaci√≥n de la aplicaci√≥n
- Gesti√≥n del estado de sesi√≥n
- Coordinaci√≥n de componentes
- Renderizado del layout principal

**Funciones Clave:**
```python
def init_session_state()  # Inicializa variables de sesi√≥n
def main()                # Funci√≥n principal de orquestaci√≥n
```

### 2. `utils/data_loader.py` - Carga de Datos

**Responsabilidades:**
- Carga optimizada del CSV
- Validaci√≥n de datos
- Feature engineering
- Filtrado din√°mico

**Funciones Clave:**
```python
@st.cache_data(ttl=3600)
def load_data() -> pd.DataFrame
    # Carga y prepara dataset
    # Returns: DataFrame con columnas derivadas

def get_filtered_data(df, filters) -> pd.DataFrame
    # Aplica filtros del usuario
    # Returns: DataFrame filtrado

def get_data_summary(df) -> Dict
    # Genera estad√≠sticas de resumen
    # Returns: Diccionario con m√©tricas
```

**Features Derivadas:**
- `shallow`: Binario para profundidad < 70 km
- `high_magnitude`: Binario para magnitud ‚â• 7.0
- `ring_of_fire`: Pertenencia al Cintur√≥n de Fuego
- `mag_category`: Categor√≠as de magnitud
- `depth_category`: Categor√≠as de profundidad

### 3. `utils/styles.py` - Estilos CSS

**Responsabilidades:**
- Tema visual personalizado
- Animaciones CSS
- Componentes responsivos
- Consistencia de dise√±o

**Clases CSS Disponibles:**
```css
.info-card        # Tarjeta informativa est√°ndar
.warning-card     # Alerta/precauci√≥n
.danger-card      # Peligro/cr√≠tico
.success-card     # √âxito/confirmaci√≥n
.main-header      # Cabecera principal
```

### 4. `components/sidebar.py` - Men√∫ Lateral

**Responsabilidades:**
- Renderizar controles de filtrado
- Gesti√≥n de estado de filtros
- Informaci√≥n contextual

**Filtros Implementados:**
- Temporales: A√±os, meses
- S√≠smicos: Magnitud, profundidad
- Tsunami: Con/sin/todos
- Geogr√°ficos: Regiones
- Visualizaci√≥n: Tema, opciones

**Return Type:**
```python
Dict[str, Any] = {
    'year_range': Tuple[int, int],
    'months': List[int],
    'magnitude_range': Tuple[float, float],
    'depth_range': Tuple[float, float],
    'tsunami_filter': str,
    'region_filter': str,
    'show_advanced': bool,
    'chart_theme': str
}
```

### 5. `components/eda.py` - An√°lisis Exploratorio

**Responsabilidades:**
- Visualizaciones estad√≠sticas
- Mapas geoespaciales
- An√°lisis de correlaciones
- Pruebas estad√≠sticas

**Subsecciones:**
1. **Distribuciones**: Histogramas, box plots, tests de normalidad
2. **Correlaciones**: Matriz de Spearman, an√°lisis de pares
3. **Geoespacial**: 4 tipos de mapas interactivos
4. **Temporal**: Evoluci√≥n anual y mensual
5. **Multivariable**: Scatter 3D, comparaciones

**Funciones Clave:**
```python
def render_eda_section(df)         # Renderiza secci√≥n completa
def render_distributions(df)       # An√°lisis de distribuciones
def render_correlations(df)        # Matriz de correlaci√≥n
def render_geospatial(df)          # Mapas interactivos
def render_temporal(df)            # Series temporales
def render_multivariate(df)        # An√°lisis multivariable
```

### 6. `components/conclusions.py` - Conclusiones

**Responsabilidades:**
- S√≠ntesis de hallazgos
- Recomendaciones estrat√©gicas
- Pr√≥ximos pasos
- Roadmap de desarrollo

**Subsecciones:**
- Hallazgos principales
- Recomendaciones para alertas
- Estrategias de modelado
- Mejoras en monitoreo

### 7. `components/ml.py` - Machine Learning

**Responsabilidades:**
- Roadmap de desarrollo ML
- Arquitectura propuesta
- Demo interactiva (simulaci√≥n)
- Recursos y documentaci√≥n

**Estado Actual:** Planificaci√≥n y dise√±o

## üìä Optimizaciones de Rendimiento

### Caching

```python
@st.cache_data(ttl=3600)  # Cache de 1 hora
def load_data():
    # Los datos se cargan una vez y se cachean
    # Invalidaci√≥n autom√°tica despu√©s de 1 hora
```

**Beneficios:**
- Carga instant√°nea en navegaci√≥n
- Reducci√≥n de I/O de disco
- Mejor experiencia de usuario

### Sampling en Visualizaciones

Para datasets grandes, las visualizaciones complejas usan muestreo:

```python
# Scatter 3D con m√°ximo 1000 puntos
df.sample(min(1000, len(df)))
```

### Lazy Loading

Los componentes se renderizan solo cuando son visibles (tabs).

## üîê Seguridad y Validaci√≥n

### Validaci√≥n de Datos

```python
# Verificaci√≥n de columnas requeridas
required_cols = ['magnitude', 'depth', 'latitude', 'longitude', ...]
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    raise ValueError(f"Faltan columnas: {missing_cols}")
```

### Sanitizaci√≥n de Inputs

- Todos los filtros tienen rangos v√°lidos
- No se permite entrada de c√≥digo arbitrario
- Validaci√≥n de tipos de datos

### XSRF Protection

Habilitado en configuraci√≥n:
```toml
[server]
enableXsrfProtection = true
```

## üß™ Testing (Planificado)

### Unit Tests

```python
# tests/test_data_loader.py
def test_load_data():
    df = load_data()
    assert 'magnitude' in df.columns
    assert len(df) > 0
    assert df['tsunami'].isin([0, 1]).all()

def test_get_filtered_data():
    df = load_data()
    filters = {'year_range': (2010, 2020)}
    filtered = get_filtered_data(df, filters)
    assert filtered['Year'].min() >= 2010
    assert filtered['Year'].max() <= 2020
```

### Integration Tests

```python
# tests/test_integration.py
def test_full_pipeline():
    # Cargar ‚Üí Filtrar ‚Üí Visualizar
    pass
```

## üìà M√©tricas de Rendimiento

### Tiempos de Carga Objetivo

- Carga inicial: < 3 segundos
- Cambio de filtros: < 1 segundo
- Renderizado de gr√°ficos: < 2 segundos
- Cambio de tabs: < 0.5 segundos

### Uso de Memoria

- Datos base: ~10-50 MB
- Visualizaciones: ~50-100 MB
- Total estimado: < 200 MB

## üîÑ Actualizaci√≥n de Datos

### Flujo Actual (Manual)

1. Descargar nuevos datos del USGS
2. Reemplazar CSV en `data/`
3. Reiniciar aplicaci√≥n (cache se invalida)

### Flujo Futuro (Autom√°tico)

```python
# Propuesta para integraci√≥n con API USGS
@st.cache_data(ttl=3600)
def fetch_latest_data():
    # Llamada a USGS API
    # Merge con datos hist√≥ricos
    # Update incremental
    pass
```

## üé® Personalizaci√≥n

### Modificar Tema

Editar `app/.streamlit/config.toml`:

```toml
[theme]
primaryColor = "#TU_COLOR"
backgroundColor = "#TU_COLOR"
# ...
```

### Agregar Nuevas Visualizaciones

```python
# En components/eda.py
def render_new_analysis(df: pd.DataFrame):
    st.markdown("### Mi Nuevo An√°lisis")
    # Tu c√≥digo aqu√≠
    
# En render_eda_section():
with new_tab:
    render_new_analysis(df)
```

### Agregar Nuevos Filtros

```python
# En components/sidebar.py
new_filter = st.selectbox("Nuevo Filtro", options=[...])

# Return en diccionario:
return {
    # ... filtros existentes
    'new_filter': new_filter
}
```

## üêõ Debugging

### Activar Modo Debug

```bash
streamlit run app.py --logger.level=debug
```

### Ver Estado de Sesi√≥n

```python
# Agregar temporalmente en app.py
st.write(st.session_state)
```

### Profiling

```python
import cProfile
import pstats

with cProfile.Profile() as pr:
    # Tu c√≥digo
    
stats = pstats.Stats(pr)
stats.sort_stats('cumtime')
stats.print_stats(10)
```

## üìù Contribuci√≥n al C√≥digo

### Convenciones

- **Docstrings**: Todas las funciones p√∫blicas
- **Type Hints**: Uso obligatorio
- **Comentarios**: Secciones claras con separadores `===`
- **Naming**: snake_case para funciones, PascalCase para clases

### Pre-commit Checklist

- [ ] C√≥digo documentado
- [ ] Type hints agregados
- [ ] Sin hardcoded paths
- [ ] Funciona con datos de ejemplo
- [ ] README actualizado si es necesario

## üöÄ Despliegue

### Streamlit Cloud

```bash
# 1. Push a GitHub
git push origin main

# 2. Conectar en streamlit.io
# 3. Seleccionar repo y app.py
# 4. Deploy autom√°tico
```

### Docker (Futuro)

```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "app.py"]
```

## üìû Soporte

Para preguntas t√©cnicas:
- Revisar esta documentaci√≥n
- Consultar README.md
- Abrir issue en GitHub
- Contactar al equipo de desarrollo

---

**√öltima actualizaci√≥n:** 2025  
**Mantenido por:** Sistema de An√°lisis S√≠smico
